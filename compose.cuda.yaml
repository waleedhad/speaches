# include:
#   - compose.observability.yaml
services:
  speaches:
    extends:
      file: compose.yaml
      service: speaches
    # NOTE: slightly older cuda version is available under 'latest-cuda-12.4.1' and `latest-cuda-12.6.3` tags
    image: ghcr.io/speaches-ai/speaches:latest-cuda
    build:
      args:
        BASE_IMAGE: nvidia/cuda:12.9.0-cudnn-runtime-ubuntu24.04
    volumes:
      - /var/speaches:/home/ubuntu/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
