# include:
#   - compose.observability.yaml
services:
  speaches:
    extends:
      file: compose.yaml
      service: speaches
    # NOTE: slightly older cuda version is available under 'latest-cuda-12.4.1' and `latest-cuda-12.6.3` tags
    image: ghcr.io/speaches-ai/speaches:latest-cuda
    user: "1000:1000"
    build:
      args:
        BASE_IMAGE: nvidia/cuda:12.9.0-cudnn-runtime-ubuntu24.04
    volumes:
      - hf-hub-cache:/home/ubuntu/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
       LOOPBACK_HOST_URL: http://10.0.0.5:8001
       OPENAI_API_KEY: bjqgm1z67NRAgPuUZWpVp859agP1ia
       OPENAI_BASE_URL: http://10.0.0.5:8001
volumes:
  hf-hub-cache:
